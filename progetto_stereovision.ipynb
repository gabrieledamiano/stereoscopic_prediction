{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ae84ed-ed22-4e44-8315-82db441db4b2",
   "metadata": {},
   "source": [
    "Progetto: FROM SINGLE RGB TO STEREOSCOPIC IMAGE (predizione dell'obiettivo di destra da quello sinistro)\n",
    "\n",
    "Prof: Nicola Felice Capece\n",
    "\n",
    "Studenti: Gabriele Damiano 69292 Francescopio Pascale 69306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327a54d-3425-4491-9626-25fb3df907b6",
   "metadata": {},
   "source": [
    "CELLA 1: Installazione e Importazione delle Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3e0479-6251-4279-9a6e-3d7324d059b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (10.4.0)\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from scikit-image) (1.14.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from scikit-image) (2024.8.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progettovisione\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python numpy matplotlib scikit-image pillow gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00c36ada-3ae5-429b-806f-420eacc08525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gdown\n",
    "import zipfile\n",
    "from tqdm import tqdm \n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b960071-ad3a-4a10-8db8-bb42e2914fef",
   "metadata": {},
   "source": [
    "CELLA 2: Scaricamento ed Estrazione del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a751a-dd57-44ff-af69-b7d7ff3dce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificare questa variabile per cambiare la base del percorso (TuoPercorso è un placeholder)\n",
    "base_dir = r'C:/TuoPercorso'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb7ed8-7deb-4122-912a-296a9c8ef369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID del file su Google Drive e URL di download\n",
    "file_id = \"1My6oQaHzclxRrKID-mylvs6Z0d5pT_Cu\"\n",
    "\n",
    "def download_with_progress(url, output_path):\n",
    "    with tqdm(total=100, desc=\"Scaricamento\", unit='%', ncols=100) as pbar:\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "        pbar.update(100)  \n",
    "\n",
    "# Funzione per scaricare ed estrarre il dataset\n",
    "def download_and_extract_dataset(file_id, download_path, extract_path):\n",
    "    if not os.path.exists(extract_path):\n",
    "        os.makedirs(download_path, exist_ok=True)\n",
    "        zip_path = os.path.join(download_path, \"Flickr1024.zip\")\n",
    "\n",
    "        # Scarica il file zip da Google Drive\n",
    "        print(\"Scaricamento del dataset da Google Drive...\")\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        download_with_progress(url, zip_path)  \n",
    "        print(\"Scaricamento completato.\")\n",
    "        \n",
    "        print(\"Estrazione del dataset...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"Estrazione completata.\")\n",
    "    else:\n",
    "        print(\"Dataset già presente in locale.\")\n",
    "\n",
    "dataset_dir = os.path.join(base_dir, 'dataset', 'Flickr1024')\n",
    "download_path = os.path.dirname(dataset_dir)  # Directory dove scaricare il file zip\n",
    "extract_path = dataset_dir                    # Directory dove estrarre il dataset\n",
    "\n",
    "\n",
    "download_and_extract_dataset(file_id, download_path, extract_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075f3ec-d019-4a73-9899-dbda875c9073",
   "metadata": {},
   "source": [
    "CELLA 3: Caricamento e Preprocessamento del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f47fa4d6-7643-4afb-b119-5e1b508df449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 800 left images, 800 right images\n",
      "Validation set: 112 left images, 112 right images\n",
      "Test set: 112 left images, 112 right images\n"
     ]
    }
   ],
   "source": [
    "# Funzione per caricare e preprocessare le immagini\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)  \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converte BGR in RGB\n",
    "    image = cv2.resize(image, (256, 256))  # Ridimensiona l'immagine a 256x256 pixel\n",
    "    image = image / 255.0  # Normalizza i valori dei pixel tra 0 e 1\n",
    "    return image.astype(np.float32) \n",
    "\n",
    "# Funzione per caricare i percorsi delle immagini da ciascuna cartella\n",
    "def load_data_from_split(base_dir, split):\n",
    "    split_dir = os.path.join(base_dir, split)\n",
    "    left_images = sorted([os.path.join(split_dir, img) for img in os.listdir(split_dir) if img.endswith('_L.png')])\n",
    "    right_images = sorted([os.path.join(split_dir, img) for img in os.listdir(split_dir) if img.endswith('_R.png')])\n",
    "    return left_images, right_images\n",
    "\n",
    "# Caricamento delle immagini per ciascuna cartella\n",
    "left_train, right_train = load_data_from_split(base_dir, 'Train')\n",
    "left_val, right_val = load_data_from_split(base_dir, 'Validation')\n",
    "left_test, right_test = load_data_from_split(base_dir, 'Test')\n",
    "\n",
    "print(f\"Train set: {len(left_train)} left images, {len(right_train)} right images\")\n",
    "print(f\"Validation set: {len(left_val)} left images, {len(right_val)} right images\")\n",
    "print(f\"Test set: {len(left_test)} left images, {len(right_test)} right images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a053f50-e26d-4d4a-a62e-478be18cde38",
   "metadata": {},
   "source": [
    "CELLA 4: Creazione della Pipeline del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da5cf1f9-e7d9-41c1-a99c-1a85ce3f40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(left_path, right_path):\n",
    "    left_path = left_path.decode('utf-8')\n",
    "    right_path = right_path.decode('utf-8')\n",
    "    left_image = load_image(left_path)\n",
    "    right_image = load_image(right_path)\n",
    "    return left_image, right_image\n",
    "\n",
    "def create_dataset(left_images, right_images):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((left_images, right_images))\n",
    "    \n",
    "    # Applica la funzione di preprocessamento\n",
    "    dataset = dataset.map(lambda x, y: tf.numpy_function(preprocess, [x, y], [tf.float32, tf.float32]))\n",
    "    \n",
    "    # Garantisce che ogni immagine abbia la forma corretta\n",
    "    dataset = dataset.map(lambda x, y: (tf.ensure_shape(x, [256, 256, 3]), \n",
    "                                        tf.ensure_shape(y, [256, 256, 3])))\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=1000)     \n",
    "    dataset = dataset.batch(32)     \n",
    "    dataset = dataset.repeat()  # Ripete i dati     \n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Creazione dei dataset per training e validation\n",
    "train_dataset = create_dataset(left_train, right_train)\n",
    "val_dataset = create_dataset(left_val, right_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2496c56-dd76-4e0f-9303-8d80740c026c",
   "metadata": {},
   "source": [
    "CELLA 5: Definizione dell'Architettura Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f42f6c-8828-4594-8a6c-622263dc3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined loss function: SSIM + RMSE\n",
    "def combined_ssim_rmse_loss(y_true, y_pred):\n",
    "    # SSIM loss inversa\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    # RMSE loss\n",
    "    rmse_loss = tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "    # Peso per bilanciare le metriche\n",
    "    alpha = 0.3\n",
    "    return alpha * ssim_loss + (1 - alpha) * rmse_loss\n",
    "\n",
    "# Costruzione dell'autoencoder \n",
    "def build_autoencoder(input_shape):\n",
    "    initializer = tf.keras.initializers.he_normal()  # He Normal per inizializzare i pesi\n",
    "\n",
    "    # Encoder\n",
    "    encoder_input = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)(encoder_input)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)(x)\n",
    "    encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder \n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)(encoded)\n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)(x)\n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)(x)  \n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x) \n",
    "    decoded = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same', kernel_initializer='glorot_uniform')(x)  # Output range [0, 1]\n",
    "\n",
    "    autoencoder = tf.keras.Model(encoder_input, decoded)\n",
    "    return autoencoder\n",
    "\n",
    "# Costruzione e compilazione del modello\n",
    "input_shape = (256, 256, 3)\n",
    "autoencoder = build_autoencoder(input_shape)\n",
    "optAdam = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "autoencoder.compile(optimizer=optAdam, loss=combined_ssim_rmse_loss)\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'inserisci_nome_modello.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Addestramento\n",
    "history = autoencoder.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(left_train) // 32,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(left_val) // 32,\n",
    "    callbacks=[checkpoint_callback, early_stopping]\n",
    ")\n",
    "\n",
    "# Salvataggio Loss \n",
    "def save_loss_plot(history, file_name_prefix='combined_loss_plot'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{file_name_prefix}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "save_loss_plot(history, file_name_prefix='combined_loss_plot')\n",
    "\n",
    "# Salvataggio modello addestrato corrente\n",
    "autoencoder.save('inserisci_nome_modello.keras')\n",
    "\n",
    "# Salvataggio dell'addestramento\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6447e4-7c93-41d9-8972-9107b5ee6489",
   "metadata": {},
   "source": [
    "CELLA 6: Caricamento di un Modello già addestrato e della Cronologia di Addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b4751-0633-41cf-8a02-ad9c9c09729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA BENE: complete_autoencoder_combined_ssim_rmse.keras fa riferimento al modello base utilizzato per testare il codice; è possibile scegliere \n",
    "#un nome a proprio piacimento per i modelli personali\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def combined_ssim_rmse_loss(y_true, y_pred):\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    rmse_loss = tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "    alpha = 0.3\n",
    "    return alpha * ssim_loss + (1 - alpha) * rmse_loss\n",
    "\n",
    "# Carica il modello completo\n",
    "autoencoder = load_model('complete_autoencoder_combined_ssim_rmse.keras', custom_objects={'combined_loss': combined_ssim_rmse_loss})\n",
    "\n",
    "# Carica la cronologia dell'addestramento\n",
    "with open('training_history_combined_ssim_rmse.json', 'r') as f:\n",
    "    history_data = json.load(f)\n",
    "\n",
    "# Funzione per plottare la cronologia caricata\n",
    "def plot_loaded_history(history_data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_data['loss'], label='Training Loss')\n",
    "    plt.plot(history_data['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizza il grafico della loss\n",
    "plot_loaded_history(history_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60619379-21e5-4c03-8f59-e8d2590b436e",
   "metadata": {},
   "source": [
    "CELLA 7: Visualizzazione dei Risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85a846-1a14-4960-9f64-d95cd2330fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione dei risultati di un campione\n",
    "def display_samples(autoencoder, left_images, right_images, num_samples=3, save_path=None):\n",
    "    random_indices = random.sample(range(len(left_images)), num_samples)\n",
    "\n",
    "    plt.figure(figsize=(12, 4 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        left_image_path = left_images[idx]\n",
    "        right_image_path = right_images[idx]\n",
    "\n",
    "        # Carica l'immagine sinistra e quella reale destra\n",
    "        left_image = load_image(left_image_path)\n",
    "        right_image = load_image(right_image_path)\n",
    "\n",
    "        # Espandi dimensione e predici l'immagine destra\n",
    "        left_image_expanded = np.expand_dims(left_image, axis=0)\n",
    "        predicted_image = autoencoder.predict(left_image_expanded)[0]\n",
    "        predicted_image = np.clip(predicted_image, 0, 1)  # Limita i valori a [0, 1]\n",
    "\n",
    "        # Denormalizza le immagini per la visualizzazione\n",
    "        left_image_vis = (left_image * 255).astype(np.uint8)\n",
    "        right_image_vis = (right_image * 255).astype(np.uint8)\n",
    "        predicted_image_vis = (predicted_image * 255).astype(np.uint8)\n",
    "\n",
    "        # Mostra le immagini\n",
    "        plt.subplot(num_samples, 3, i * 3 + 1)\n",
    "        plt.title(f'Esempio {i+1} - IMMAGINE SINISTRA')\n",
    "        plt.imshow(left_image_vis)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_samples, 3, i * 3 + 2)\n",
    "        plt.title(f'Esempio {i+1} - IMMAGINE DESTRA PREDETTA')\n",
    "        plt.imshow(predicted_image_vis)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_samples, 3, i * 3 + 3)\n",
    "        plt.title(f'Esempio {i+1} - IMMAGINE DESTRA REALE')\n",
    "        plt.imshow(right_image_vis)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvataggio grafico\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='png', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualizza e salva tre campioni casuali\n",
    "display_samples(autoencoder, left_val, right_val, num_samples=3, save_path=\"esempi_predizioni.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8eb740-5e5f-4308-80f4-81c7e4411ecb",
   "metadata": {},
   "source": [
    "CELLA 8: Calcolo delle Metriche di Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144e4e9-0a8e-4efb-be31-d888c6ca59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(autoencoder, dataset, num_batches=None):\n",
    "    mse_scores = []\n",
    "    psnr_scores = []\n",
    "    ssim_scores = []\n",
    "    \n",
    "    # Prende un subset del dataset (solo num_batches batch se specificato)\n",
    "    dataset_to_evaluate = dataset.take(num_batches) if num_batches else dataset\n",
    "\n",
    "    for batch_count, (left_images, right_images) in enumerate(dataset_to_evaluate, start=1):\n",
    "        print(f\"Processing batch {batch_count}...\")  # Output del batch corrente\n",
    "\n",
    "        # Previsione  dele immagini destre\n",
    "        predicted_right_images = autoencoder.predict(left_images)\n",
    "\n",
    "\n",
    "        right_images_np = right_images.numpy()\n",
    "        predicted_right_images_np = predicted_right_images\n",
    "\n",
    "        # Calcola le metriche per ogni immagine nel batch\n",
    "        for true_image, pred_image in zip(right_images_np, predicted_right_images_np):\n",
    "            # MSE\n",
    "            mse = np.mean((true_image - pred_image) ** 2)\n",
    "            mse_scores.append(mse)\n",
    "\n",
    "            # PSNR\n",
    "            psnr_value = psnr(true_image, pred_image, data_range=1.0)\n",
    "            psnr_scores.append(psnr_value)\n",
    "\n",
    "            # SSIM con controllo dinamico di win_size\n",
    "            min_dimension = min(true_image.shape[0], true_image.shape[1])\n",
    "            win_size = min(7, min_dimension)  # Finestra SSIM dinamica\n",
    "            ssim_value = ssim(true_image, pred_image, channel_axis=-1, win_size=win_size, data_range=1.0)\n",
    "            ssim_scores.append(ssim_value)\n",
    "        \n",
    "        # Feedback ogni 10 batch\n",
    "        if batch_count % 10 == 0:\n",
    "            print(f\"Processati {batch_count} batch...\")\n",
    "\n",
    "    # Calcola i valori medi e massimi delle metriche\n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    avg_psnr = np.mean(psnr_scores)\n",
    "    avg_ssim = np.mean(ssim_scores)\n",
    "\n",
    "    max_mse = np.max(mse_scores)\n",
    "    max_psnr = np.max(psnr_scores)\n",
    "    max_ssim = np.max(ssim_scores)\n",
    "\n",
    "    print(\"Valutazione completata.\")\n",
    "    return avg_mse, avg_psnr, avg_ssim, max_mse, max_psnr, max_ssim\n",
    "\n",
    "avg_mse, avg_psnr, avg_ssim, max_mse, max_psnr, max_ssim = evaluate_model(autoencoder, val_dataset, num_batches=32)\n",
    "\n",
    "print(f\"MSE Medio: {avg_mse}\")\n",
    "print(f\"PSNR Medio: {avg_psnr}\")\n",
    "print(f\"SSIM Medio: {avg_ssim}\")\n",
    "print(f\"MSE Massimo: {max_mse}\")\n",
    "print(f\"PSNR Massimo: {max_psnr}\")\n",
    "print(f\"SSIM Massimo: {max_ssim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c28a9b-0753-41a9-a060-42511f4a7ca7",
   "metadata": {},
   "source": [
    "CELLA 9: Salvataggio delle Metriche come Immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bdd071e-00a9-40b3-a877-1babdbf01f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabella delle metriche salvata come evaluation_metrics_rmse_ssim.png\n"
     ]
    }
   ],
   "source": [
    "def save_metrics_as_table(metrics, file_name=\"evaluation_metrics.png\"):\n",
    "    \"\"\"\n",
    "    Salva le metriche di valutazione come immagine in formato tabellare.\n",
    "    \n",
    "    Parametri:\n",
    "    - metrics: dizionario contenente i nomi delle metriche e i relativi valori.\n",
    "    - file_name: nome del file immagine di output.\n",
    "    \"\"\"\n",
    "    # Creazione della figura\n",
    "    fig, ax = plt.subplots(figsize=(8, 2)) \n",
    "\n",
    " \n",
    "    metrics_data = [[key, f\"{value:.4f}\"] for key, value in metrics.items()]\n",
    "\n",
    "    # Creazione dela tabella\n",
    "    table = ax.table(cellText=metrics_data, colLabels=[\"Metrica\", \"Valore\"], cellLoc=\"center\", loc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.2) \n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Salvataggio dela tabella come immagine\n",
    "    plt.savefig(file_name, format=\"png\", dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"Tabella delle metriche salvata come {file_name}\")\n",
    "\n",
    "# Dizionario\n",
    "metrics = {\n",
    "    \"MSE Medio\": avg_mse,\n",
    "    \"PSNR Medio\": avg_psnr,\n",
    "    \"SSIM Medio\": avg_ssim,\n",
    "    \"MSE Massimo\": max_mse,\n",
    "    \"PSNR Massimo\": max_psnr,\n",
    "    \"SSIM Massimo\": max_ssim\n",
    "}\n",
    "\n",
    "# Salvataggio metriche\n",
    "save_metrics_as_table(metrics, file_name=\"evaluation_metrics_rmse_ssim.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e972f5-2a73-4017-9131-6b691a79be50",
   "metadata": {},
   "source": [
    "CELLA 10: Predizione su Dati di Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0026eb2-8e4b-42c2-9e90-c9700966d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_images(base_dir):\n",
    "    test_dir = os.path.join(base_dir, 'Test')\n",
    "    left_test_images = sorted([os.path.join(test_dir, img) for img in os.listdir(test_dir) if img.endswith('_L.png')])\n",
    "    return left_test_images\n",
    "    \n",
    "# Funzione di preprocessamento per il test (solo immagine sinistra)\n",
    "def preprocess_test(left_path):\n",
    "    left_path = left_path.decode('utf-8') \n",
    "    left_image = load_image(left_path)  # Carica l'immagine sinistra\n",
    "    return tf.cast(left_image, tf.float32)\n",
    "\n",
    "# Funzione per creare il dataset di test (solo immagini sinistre)\n",
    "def create_test_dataset(left_images):\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(left_images)\n",
    "    \n",
    "    # Applica la funzione di preprocessamento solo per l'immagine sinistra\n",
    "    test_dataset = test_dataset.map(lambda x: tf.numpy_function(preprocess_test, [x], [tf.float32]))\n",
    "    \n",
    "    test_dataset = test_dataset.map(lambda x: tf.ensure_shape(x, [256, 256, 3]))\n",
    "    \n",
    "    test_dataset = test_dataset.batch(16)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return test_dataset\n",
    "\n",
    "left_test_images = load_test_images(base_dir)  # Carica le immagini di test\n",
    "test_dataset = create_test_dataset(left_test_images)  # Crea il dataset di test\n",
    "\n",
    "# Funzione per predire e visualizzare i risultati delle immagini di test\n",
    "def predict_and_compare(model, test_dataset):\n",
    "    for left in test_dataset.take(1): \n",
    "        predictions = model.predict(left)\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "        fig.subplots_adjust(hspace=0.4, wspace=0.3)  \n",
    "\n",
    "        for i in range(3):  # Mostra le prime 3 immagini\n",
    "            # Immagine sinistra (reale)\n",
    "            axes[i, 0].imshow(left[i].numpy())\n",
    "            axes[i, 0].set_title('IMMAGINE SINISTRA')\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            # Immagine destra predetta\n",
    "            axes[i, 1].imshow(predictions[i])\n",
    "            axes[i, 1].set_title('IMMAGINE DESTRA PREDETTA')\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "predict_and_compare(autoencoder, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79082f0-9da1-4aba-be3b-0cae362d529a",
   "metadata": {},
   "source": [
    "CELLA 11: Predizione su Immagini Esterne e Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720431cc-9ca2-47ef-bf5d-b5491b0c1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_custom_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "    image = cv2.resize(image, (256, 256))  \n",
    "    image = image / 255.0 \n",
    "    image = np.expand_dims(image, axis=0)  \n",
    "    return image\n",
    "\n",
    "# Funzione per eseguire la previsione e visualizzare i risultati su un'immagine esterna\n",
    "def predict_on_custom_image(model, image_path):\n",
    "    # Carica e preprocessa l'immagine esterna\n",
    "    left_image = load_and_preprocess_custom_image(image_path)\n",
    "    prediction = model.predict(left_image)[0]  # Ottieni la predizione per l'immagine\n",
    "\n",
    "    # Denormalizza per la visualizzazione (da [0, 1] a [0, 255])\n",
    "    left_image_vis = (left_image[0] * 255).astype(np.uint8)\n",
    "    predicted_image_vis = np.clip(prediction * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Visualizza l'immagine originale e quella predetta\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Immagine sinistra (originale)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('IMMAGINE SINISTRA (CUSTOM)')\n",
    "    plt.imshow(left_image_vis)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Immagine destra predetta\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('IMMAGINE DESTRA PREDETTA')\n",
    "    plt.imshow(predicted_image_vis)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Esempio di utilizzo con una immagine esterna\n",
    "custom_image_path = '/inserisci/percorso/immagine'  \n",
    "predict_on_custom_image(autoencoder, custom_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
